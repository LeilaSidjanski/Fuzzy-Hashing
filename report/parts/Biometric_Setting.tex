\include{Introduction.tex}
\section{Biometric Setting}
This section provides a comprehensive overview of the mathematical and technical aspects involved in fingervein matching, which is essential for comprehending the subsequent discussions in this paper. Additionally, we will provide insight into the process of obtaining these equations and statements, evaluating their relevance and implications within the context of our research. 

\subsection{Biometric Data and Similarity Scores}
%biometric template = is the reference model obtained from the finger images, represented as a vector
%Biometric capture = actual data obtained from the finger image during enrollement or authentication, represented as a bitstring X of length n
We begin by delving into the representation of the biometric data. Finger images, designated as biometric templates and formated as \(250\)x\(386\), result in n = \(96'500\) pixels per image. To enhance processing efficiency, these templates are converted into vectors, departing from their original 2-dimension image structure. 

In the biometric context, each finger serves as a biometric subject, with a corresponding biometric capture represented as a bitstring \(X\) of length \(n\). This capture encapsulates the specific vein pixel information extracted from the finger image, while the biometric template serves as a reference mode derived from these images. 

Each of the \(n\) bits of the biometric capture is designated as \(X_1\),..., \(X_n\), with \(X_i\) set to \(1\) if the \(i\)-th bit corresponds to a vein and \(0\) otherwise. In the case where \(i\) is a \hyperref[def:Uniform Distribution]{uniformly distributed} random index and \(X\) is randomly chosen, we define the probability of pixel \(X_i\) being a vein 

\begin{equation} \label{eq:proba}
    Pr[X_i = 1] = p \approx 3.3 \% 
\end{equation}

In biometric authentication and identification, the uniqueness of each biometric capture is encoded in its bits. The objective revolves around discerning the similarity between two biometric captures to verify or identify two individuals. Therefore, the scoring mechansim plays a crucial role in quantatively determining the similarity between biometric captures. This similarity score holds significance in verifying the identity of an individual (authentication) or identifying potential matches in a database (identification). A higher score indicates a greater ressemblance between captures, while a lower score suggests less similarity. This scoring mechanism is indispensable for ensuring the accuracy and reliability of biometric systems. The score of (\(X\), \(Y\)) is computed as

\begin{equation} \label{eq:score}
    \begin{aligned}
        Score(X, Y) &= \frac{HW(X \land Y)}{HW(X) + HW(Y)}\\
        &= \frac{1}{2}-\frac{1}{2}\frac{d_H(X, Y)}{HW(X) + HW(Y)}
    \end{aligned}
\end{equation}

where \(HW\) denotes the \hyperref[def:Hamming Weight]{Hamming Weight} and \(d_H\) the \hyperref[def:Hamming Distance]{Hamming Distance}. 

In conjunction with the scoring mechanism, Miura matching emerges as a specialized technique for comparing biometric samples. This method entails determining an optimal offset translation, denoted as \(d_X\) and \(d_Y\), between two biometric samples to align their features for comparison, thereby compensating for differences in positioning or orientation. The alignment process is maximizes the similarity score, defined as:

\[Score = \text{Score}(d_X \cdot X, d_Y \cdot Y)\]

Once the optimal offsets, \(d_X\) and \(d_Y\), are determined, they are applied to the original samples for alignment. This results in the calculated aligned positions, denoted as \(\bar{X}\) and \(\bar{Y}\), such that:

\[\bar{X} = d_X \cdot X\]
\[\bar{Y} = d_Y \cdot Y\]

Miura matching and the scoring mechanism are interconnected components, where Miura matching facilitates the computation of the score, thereby offering insights into the similarity between biometric captures and enhancing the reliability of matching algorithms.

The probability of the \(i\)-th pixel of two captures not being the same after applying the optimal offset translations depends on the distribution of (\(X\), \(Y\)), and is denoted as \(\delta\)

\begin{equation} \label{eq:delta}
    \begin{aligned}
        \delta &= Pr[\bar{X}_i \neq \bar{Y}_i]\\
        &= \frac{1}{n}E(d_h(\bar{X}, \bar{Y}))
    \end{aligned}
\end{equation}

It is crucial to distinguish between the types of distributions associated with the two captures. When both captures originate from the same biometric subject, we refer to it as the $\delta_{same}$. Conversely, if the captures are from different subjects, we label it as $\delta_{diff}$. Additionally, when \(X\) and \(Y\) consist of \(2n\) independent random bits with an expected value of \(p\) and no optimal offset is applied, we classify it as $\delta_{indep}$ In this scenario, \(\delta_{indep}\) = \(2p(1-p)\). These distinctions produce the following figures: 

\begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.25}\begin{tabular}{|c|c|c|}
        \hline
        $\delta_{same}$ & $\delta_{diff}$ & $\delta_{indep}$\\
        \hline
        $4.8\%$ & $6.1\%$ & $6.9\%$\\
        \hline
    \end{tabular}
\caption{Comparison of Distributions: $\delta_{same}$, $\delta_{diff}$, and $\delta_{indep}$}
\end{table}

Utilizing $p$ (\ref{eq:proba}) and $\delta$ (\ref{eq:delta}), we derive the joint distribution for (\(\bar{X}_j\), \(\bar{Y}_j\)) across \(j\) random instances:

\begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.5}
    \begin{tabular}{|c|c|c|}
        \hline
        & $\bar{Y}_i = 0$ & $\bar{Y}_i = 1$\\
        \hline
        $\bar{X}_i = 0$ & $1 - p - \frac{\delta}{2}$ & $\frac{\delta}{2}$\\
        \hline
        $\bar{X}_i = 1$ & $\frac{\delta}{2}$ & $p - \frac{\delta}{2}$\\
        \hline
    \end{tabular}
    \caption{Joint Distribution of ($\bar{X}_j$, $\bar{Y}_j$) for Random Instances}
\end{table}

\subsection{Experimental Derivation of the Probability \(p\)}

In order to derive the probability that a uniformly distributed random pixel is a vein, $p$ (\ref{eq:proba}), we utilized a dataset comprising 20 unique individuals. Each individual contributed images of both right and left index/middle fingers, with 5 trials per finger, captured using 2 different cameras. This methodology resulted in a comprehensive dataset of 800 images. As described in Section~\ref{sec:extraction-pipeline}, we implemented Simon's optimal pipeline to extract the feature vectors from each image in the dataset (refer to Figure~\ref{pipeline_simon}). Building on preliminary work by Burcu, we further analyzed these feature vectors to gain statistical insights into vein patterns.

This analysis is carried out by the \textit{analyze\_single\_image} algorithm, located in the \textit{Fuzzy\_Hashing/experiment\_p\_value/verify\_p\_parameter.ipynb} notebook. The algorithm processes the dataset's feature vectors, performing two main functions:
\begin{enumerate}
    \item For each pixel position, it updates the \textit{veins[i]} array, which accumulates detections of veins across all images for each camera \(i={1,2}\).
    \item It maintains a count of the number of images analyzed per camera \(i={1,2}\) in the \textit{image\_count[i]} array.
\end{enumerate}

Following the processing of all feature vectors, the algorithm computes the probability of a pixel being part of a vein by dividing the aggregated vein detections by the total number of images analyzed, across both cameras. We generated visual representations depicting the distribution of detected vein pixels for each camera individually and for the combined data from both cameras.

\begin{enumerate}
    \item \textbf{Camera 1 and Camera 2 distribution}: The following histograms showcase the frequency distribution of vein pixels detected in images captured by Camera 1 and 2 individually, with a Gaussian fit overlaid to highlight the data's normal distribution trend.

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{latex-img/distribution_veins_cam1.png}
        \caption{Vein Pixel Distribution Analysis Using Camera 1: Histogram Representation with Gaussian Fit Overlay}
        \label{distribution_veins_cam1}
    \end{figure}

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{latex-img/distribution_veins_cam2.png}
        \caption{Vein Pixel Distribution Analysis Using Camera 2: Histogram Representation with Gaussian Fit Overlay}
        \label{distribution_veins_cam2}
    \end{figure}


    \item \textbf{Combined Cameras Distribution}: To understand the aggregate behavior of vein detection across both cameras, we merged the data, generating a comprehensive histogram with a Gaussian fit.

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{latex-img/distribution_veins_bothcams.png}
        \caption{Aggregate Vein Pixel Distribution Analysis: Combined Histogram and Gaussian Fit from Both Cameras}
        \label{distribution_veins_bothcams}
    \end{figure}

\end{enumerate}

Concluding our analysis of the vein pixel distribution across different camera captures and their aggregate dataset, we computed the average probability \(p\) that a given pixel corresponds to a vein. The process involved summing up all vein-identifying pixels within the datasets for Camera 1, Camera 2, and the combined dataset. We then divided this sum by the total number of pixels processed, multiplying the count of images by the total pixels per image, to ascertain the average likelihood \(p\) that any randomly selected pixel is part of a vein pattern.

The findings from this analysis revealed the following probabilities:
\begin{enumerate}
    \item For Camera 1, the probability \(p = Pr[X_i = 1]\) was calculated to be 0.0342, indicating a 3.42\% chance that any given pixel in images from Camera 1 represents a vein.

    \item For Camera 2, the probability \(p = Pr[X_i = 1]\) was slightly lower at 0.0315, translating to a 3.15\% chance for vein representation in its images.

    \item When considering the datasets from Both Cameras combined, the probability \(p = Pr[X_i = 1]\) averaged out to 0.0329, suggesting a 3.29\% likelihood of a pixel depicting a vein across the entire dataset.
    
\end{enumerate}

These results underscore the subtle variances in vein detection probabilities between the two cameras, while also offering a comprehensive view when the datasets are merged. The close proximity of these probabilities across the datasets underscores the consistency in vein pattern detection capabilities of the imaging setups, as well as the robustness of the methodology applied for analyzing vein patterns in biometric data.

\subsection{Experimental Derivation of the Probabilities \(\delta_{\text{same}}, \delta_{\text{diff}}, \delta_{\text{indep}}\)}

% A voir si cela nous semble nécessaire de faire un dernier chapitre de conclusion sur nos résultats trouvés experimentalement ou bien si on intègre direct dans les 2 dernières subsections ci dessus