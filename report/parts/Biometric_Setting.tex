\include{Introduction.tex}
\section{Biometric Setting}
This section provides a comprehensive overview of the mathematical and technical aspects involved in fingervein matching, which is essential for comprehending the subsequent discussions in this paper. Additionally, insights into the process of obtaining these equations and statements will be provided, evaluating their relevance and implications within the context of the research. 

\subsection{Biometric Data and Similarity Scores}
\label{Bio_data_sim_scores}
We begin by delving into the representation of the biometric data. Finger images, designated as biometric templates and formated as \(250\)x\(386\), result in n = \(96'500\) pixels per image. To enhance processing efficiency, these templates are converted into vectors, departing from their original 2-dimension image structure. 

In the biometric context, each finger serves as a biometric subject, with a corresponding biometric capture represented as a bitstring \(X\) of length \(n\). This capture encapsulates the specific vein pixel information extracted from the finger image, while the biometric template serves as a reference mode derived from these images. 

Each of the \(n\) bits of the biometric capture is designated as \(X_1\),..., \(X_n\), with \(X_i\) set to \(1\) if the \(i\)-th bit corresponds to a vein and \(0\) otherwise. In the case where \(i\) is a \hyperref[def:Uniform Distribution]{uniformly distributed} random index and \(X\) is randomly chosen, the probability of pixel \(X_i\) being a vein is defined as follows:

\begin{equation} \label{eq:proba}
    Pr[X_i = 1] = p \approx 3.3 \% 
\end{equation}

In biometric authentication and identification, the uniqueness of each biometric capture is encoded in its bits. The objective revolves around discerning the similarity between two biometric captures to verify or identify two individuals. Therefore, the scoring mechansim plays a crucial role in quantatively determining the similarity between biometric captures. This similarity score holds significance in verifying the identity of an individual (authentication) or identifying potential matches in a database (identification). A higher score indicates a greater ressemblance between captures, while a lower score suggests less similarity. This scoring mechanism is indispensable for ensuring the accuracy and reliability of biometric systems. The score of (\(X\), \(Y\)) is computed as

\begin{equation} \label{eq:score}
    \begin{aligned}
        Score(X, Y) &= \frac{HW(X \land Y)}{HW(X) + HW(Y)}\\
        &= \frac{1}{2}-\frac{1}{2}\frac{d_H(X, Y)}{HW(X) + HW(Y)}
    \end{aligned}
\end{equation}

where \(HW\) denotes the \hyperref[def:Hamming Weight]{Hamming Weight} and \(d_H\) the \hyperref[def:Hamming Distance]{Hamming Distance}. 

In conjunction with the scoring mechanism, Miura matching emerges as a specialized technique for comparing biometric samples. This method entails determining an optimal offset translation, denoted as \(d_X\) and \(d_Y\), between two biometric samples to align their features for comparison, thereby compensating for differences in positioning or orientation. The alignment process maximizes the similarity score, defined as:

\[Score = \text{Score}(d_X \cdot X, d_Y \cdot Y)\]

Once the optimal offsets, \(d_X\) and \(d_Y\), are determined, they are applied to the original samples for alignment. This results in the calculated aligned positions, denoted as \(\bar{X}\) and \(\bar{Y}\), such that:

\[\bar{X} = d_X \cdot X\]
\[\bar{Y} = d_Y \cdot Y\]

Miura matching and the scoring mechanism are interconnected components, where Miura matching facilitates the computation of the score, thereby offering insights into the similarity between biometric captures and enhancing the reliability of matching algorithms.

The probability of the \(i\)-th pixel of two captures not being the same after applying the optimal offset translations depends on the distribution of (\(X\), \(Y\)), and is denoted as \(\delta\)

\begin{equation} \label{eq:delta}
    \begin{aligned}
        \delta &= Pr[\bar{X}_i \neq \bar{Y}_i]\\
        &= \frac{1}{n}E(d_h(\bar{X}, \bar{Y}))
    \end{aligned}
\end{equation}

Distinguishing between the types of distributions associated with the two captures is crucial. When both captures originate from the same biometric subject, it is referred to as the $\delta_{same}$. Conversely, if the captures are from different subjects, it is labeled as $\delta_{diff}$. Additionally, when \(X\) and \(Y\) consist of \(2n\) independent random bits with an expected value of \(p\) and no optimal offset is applied, it is classified as $\delta_{indep}$ In this scenario, \(\delta_{indep}\) = \(2p(1-p)\). These distinctions produce the following figures: 

\begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.25}\begin{tabular}{|c|c|c|}
        \hline
        $\delta_{same}$ & $\delta_{diff}$ & $\delta_{indep}$\\
        \hline
        $4.8\%$ & $6.1\%$ & $6.9\%$\\
        \hline
    \end{tabular}
\caption{Comparison of Distributions: $\delta_{same}$, $\delta_{diff}$, and $\delta_{indep}$}
\end{table}

Utilizing $p$ (\ref{eq:proba}) and $\delta$ (\ref{eq:delta}), the joint distribution for (\(\bar{X}_j\), \(\bar{Y}_j\)) across \(j\) random instances is derived:

\begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.5}
    \begin{tabular}{|c|c|c|}
        \hline
        & $\bar{Y}_i = 0$ & $\bar{Y}_i = 1$\\
        \hline
        $\bar{X}_i = 0$ & $1 - p - \frac{\delta}{2}$ & $\frac{\delta}{2}$\\
        \hline
        $\bar{X}_i = 1$ & $\frac{\delta}{2}$ & $p - \frac{\delta}{2}$\\
        \hline
    \end{tabular}
    \caption{Joint Distribution of ($\bar{X}_j$, $\bar{Y}_j$) for Random Instances}
\end{table}

\subsection{Experimental Derivation of the Probability \(p\)}

In order to derive the probability that a uniformly distributed random pixel is a vein, $p$ (\ref{eq:proba}), a dataset of 20 unique individuals was utilized. Each individual contributed images of both right and left index/middle fingers, with 5 trials per finger, captured using 2 different cameras. This methodology resulted in a comprehensive dataset of 800 images. Following the approach in Section~\ref{sec:extraction-pipeline}, Simon's optimal pipeline was implemented to extract the feature vectors from each image in the dataset (refer to Figure~\ref{pipeline_simon}). Subsequently, statistical analysis was performed on these feature vectors to gain insights into vein patterns, building on the preliminary work by Burcu. It's important to note that the calculation of the probability \(p\) does not take into account any postalignment method, like Miura Matching, even though the code might seem like it does.

This analysis is carried out by the \textit{analyze\_single\_image} algorithm, located in the \textit{Fuzzy\_Hashing/experiment\_p\_value/verify\_p\_parameter.ipynb} notebook. The algorithm processes the dataset's feature vectors, performing two main functions:
\begin{enumerate}
    \item For each pixel position, it updates the \textit{veins[i]} array, which accumulates detections of veins across all images for each camera \(i={1,2}\).
    \item It maintains a count of the number of images analyzed per camera \(i={1,2}\) in the \textit{image\_count[i]} array.
\end{enumerate}

Following the processing of all feature vectors, the algorithm computes the probability of a pixel being part of a vein by dividing the aggregated vein detections by the total number of images analyzed, across both cameras. Visual representations were generated to illustrate the distribution of detected vein pixels for each camera individually and for the combined data from both cameras.

\begin{enumerate}
    \item \textbf{Camera 1 and Camera 2 distribution}: The following histograms showcase the frequency distribution of vein pixels detected in images captured by Camera 1 and 2 individually, with a Gaussian fit overlaid to highlight the data's normal distribution trend.

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{latex-img/distribution_veins_cam1.png}
        \caption{Vein Pixel Distribution Analysis Using Camera 1: Histogram Representation with Gaussian Fit Overlay}
        \label{distribution_veins_cam1}
    \end{figure}

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{latex-img/distribution_veins_cam2.png}
        \caption{Vein Pixel Distribution Analysis Using Camera 2: Histogram Representation with Gaussian Fit Overlay}
        \label{distribution_veins_cam2}
    \end{figure}


    \item \textbf{Combined Cameras Distribution}: To understand the aggregate behavior of vein detection across both cameras, the data was merged, generating a comprehensive histogram with a Gaussian fit.

    \begin{figure}[H]
        \centering
        \includegraphics[width=1\linewidth]{latex-img/distribution_veins_bothcams.png}
        \caption{Aggregate Vein Pixel Distribution Analysis: Combined Histogram and Gaussian Fit from Both Cameras}
        \label{distribution_veins_bothcams}
    \end{figure}

\end{enumerate}

Concluding the analysis of the vein pixel distribution across different camera captures and their aggregate dataset, the average probability \(p\) that a given pixel corresponds to a vein was computed. This involved summing up all vein-identifying pixels within the datasets for Camera 1, Camera 2, and the combined dataset. Subsequently, this sum was divided by the total number of pixels processed, multiplying the count of images by the total pixels per image, to ascertain the average likelihood \(p\) that any randomly selected pixel is part of a vein pattern.

The findings from this analysis revealed the following probabilities:
\begin{enumerate}
    \item For Camera 1, the probability \(p = Pr[X_i = 1]\) was calculated to be 0.0342, indicating a 3.42\% chance that any given pixel in images from Camera 1 represents a vein.

    \item For Camera 2, the probability \(p = Pr[X_i = 1]\) was slightly lower at 0.0315, translating to a 3.15\% chance for vein representation in its images.

    \item When considering the datasets from Both Cameras combined, the probability \(p = Pr[X_i = 1]\) averaged out to 0.0329, suggesting a 3.29\% likelihood of a pixel depicting a vein across the entire dataset.
    
\end{enumerate}

\subsection{Experimental Derivation of the Probabilities \(\delta_{\text{same}}, \delta_{\text{diff}}, \delta_{\text{indep}}\)}

To assess the probability that the i-th pixel of two captures diverges after applying the optimal offset translations \( d_X \) and \( d_Y \) (Equation (\ref{eq:delta})), we undertake additional experimental analysis located in the \textit{experiment\_delta\_value} directory within our \textit{Fuzzy\_Hashing} framework. This investigation continues to utilize the same dataset comprising 20 distinct individuals. Here, the post-alignment process, specifically Miura Matching, is included in our examination as the calculation formula integrates this step. As detailed in Section~\ref{Bio_data_sim_scores}, our objective is to evaluate three distinct delta values: \(\delta_{\text{same}}, \delta_{\text{diff}}, \delta_{\text{indep}}\). The computation of \( \delta_{\text{indep}} \) is relatively straightforward, having determined the value of \( p \). The formula for \( \delta_{\text{indep}} \) relies solely on \( p \), allowing us to express it as:

\[ \delta_{\text{indep}} = 2p(1 - p) = 2 \times 0.0329 \times (1 - 0.0329) \approx 0.064 \]

This result provides an estimated 6.4\% independent delta value.

To accurately evaluate \( \delta_{\text{same}} \) and \( \delta_{\text{diff}} \), a meticulous procedure was executed on our dataset, which involves 20 unique individuals, each having multiple biometric captures. Below is an outline of the methodology applied:

\begin{enumerate}
    \item \textbf{Pairwise Comparison}: For each individual, we compared every biometric capture to every other capture within the dataset, applying the Hamming distance metric to compute the normalized distances.
    \item \textbf{Statistical Analysis}: We organized the resulting distances into two distinct categories:
    \begin{itemize}
        \item Intra-individual distances, where captures from the same individual (same finger images) were compared, forming the first group.
        \item Inter-individual distances, comprising comparisons between biometric captures from different individuals, forming the second group.
    \end{itemize}
    \item \textbf{Probability Computation}:
    \begin{itemize}
        \item For \( \delta_{\text{same}} \), we averaged the normalized distances of the intra-individual comparisons, which furnished us with the probability of observing a difference between captures from the same individual after alignment.
        \item For \( \delta_{\text{diff}} \), we performed a similar averaging of the normalized distances from the inter-individual comparisons, thereby obtaining the probability that captures from different individuals would differ.
    \end{itemize}
\end{enumerate}

The joint probability distribution presented in Table 2 represents the relationship between the variables \(\bar{X}_i\) and \(Y_i\), which compare the i-th bit of two biometric samples. The parameter \(p\) denotes the probability of a bit being '1', and by complement, \(1-p\) signifies the probability of a bit being '0'. The parameter \(\delta\) encapsulates the probability that the two bits are not identical, which can occur due to various sources of error in biometric comparison. 

In the table, the entry \(P(X_i = 0, Y_i = 0)\) corresponds to the probability of both bits being '0'. In the absence of any discrepancies (\(\delta = 0\)), this probability would be simply the product of the individual probabilities, \((1-p)^2\). However, considering that discrepancies do occur with probability \(\delta\), and that there are two distinct ways in which the bits can differ (\(X_i = 0, Y_i = 1\) and \(X_i = 1, Y_i = 0\)), we must adjust for these potential errors. Since these two error scenarios are mutually exclusive and equally likely, we subtract half the error probability, \(\frac{\delta}{2}\), from \((1-p)^2\) to obtain \(1-p-\frac{\delta}{2}\) for the probability \(P(X_i = 0, Y_i = 0)\).

The probability \(P(X_i = 1, Y_i = 1)\) is derived in an analogous manner. Without errors, it would be \(p^2\), but we must also adjust for the likelihood of discrepancies by subtracting \(\frac{\delta}{2}\). Hence, the probability is given by \(p-\frac{\delta}{2}\).

Lastly, the probabilities \(P(X_i = 0, Y_i = 1)\) and \(P(X_i = 1, Y_i = 0)\) directly represent the scenarios where the bits differ. As there are only two such cases that contribute to \(\delta\), each is allocated a probability of \(\frac{\delta}{2}\). This division ensures that the total probability of discrepancy \(\delta\) is evenly distributed among the two possible error states.

The construction of this joint distribution is crucial for modeling the behavior of biometric systems, facilitating the assessment of system accuracy by quantifying the likelihood of matching errors.




