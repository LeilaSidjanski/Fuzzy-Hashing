\section{Theoretical Framework}
Here we explain the theoretical concepts and maths that are explained in our document fuzzytext

\subsection{Biometric Setting}
Explain section 1 of the document (parameterization and representation of biometric data). Explain what biometric data is and its importance in security applications.Explain the transformation of finger pictures into compressed formats for vein pixel extraction (Simon's pipeline). Explain the probability models of section 1: introduce p and the concept of matching biometric captures with an optimal offset, denoted by sigma. to minimize the mismatch probability (p(Xi!=Yi))

\subsection{Concept of Fuzzy Hashing}
Explain what fuzzy hashing is and how it is different from standard hashing in security systems. Describe the PreHash functionality on biometric data, using random permutation to select specific indices corresponding to feature points. Explain the formula for comparing two pre-hashed biometric captures using the hamming weight and the bitwise AND operation to assess the match probability. 
Explain the calculation of the matching score, using the ratio of the hamming weight of the conjunction of two bit strings to their combined hamming weights. Explain what mu is.

\subsection{Compressed Fuzzy Hashing}
Explain how post-hash functions compress the pre-hash bit strings into a more compacted form, maintaining near uniform distribution when inputs are random. Discuss the implications of tis compression on matching probability and introduce the concept of D=2 puissance d to understand the compression ratio and its effects on hash collision probabilities.
Detail the formula calculating the probability of hash matches after compression and the role of mu in determining these probabilities, particularly how it adjusts based on the distribution of biometric captures (same, different, independent)

\subsection{Pre-Hash and Post-Hash Implementation and Analysis}
Explain the algorithm and how we have implemented it

\subsection{Applications in Biometric Macthing}
Illustrate the use of fuzzy hashing in biometric matching by employing the hamming distance to compare hashes, reducing the data required for storing biometric templates and enhancing privacy. Explain how a threhold is defined for determining a match and how false negative rates (FNR) and false positive rates (FPR) are calculated using the cumulative distirbution function (CDF) of the normal distribution, emphasizing the statistical approach to balancing match accuracy and security. 

\subsection{1:N Matching}
Discuss the challenges and strategies for matching a single biometric sample against a large database, focusing on the computational and memory complexities involved. Explain how parameters are adjusted to manage trade offs between time complexity, space complexity, and match probability. Provide insight into the statistical models used for evaluating the performance of 1:N natching systems, including the derviation of FNR and the optimization of parameters for efficient and accurate matching across large datasets. 



