\newpage
\section{Application: Private and Compact Biometric Matching}
\label{Application: Private and Compact Biometric Matching}

This section delves into the practical application of fuzzy hashing within the realm of biometric matching. Employing the Hamming distance for biometric matching offers a systematic approach by iteratively generating \textit{l} iterations of the \textit{PreHash} function, defined as:

\begin{equation}
    \begin{aligned}
        Hash_{\text{key}}^m &= Hash_{\text{key}_1, \ldots, \text{key}_l}^m(X)\\
        &= (PreHash_{\text{key}_1}^m(X), \ldots, PreHash_{\text{key}_l}^m(X))
    \end{aligned}
\end{equation}

Subsequently, the Hamming distance between the resulting hash values of two biometric samples \(X\) and \(Y\) is calculated as:

\[d_H(Hash_{key}(X), Hash_{key}(Y)) = \# \{i: PreHash_{key_i}(X) \neq PreHash_{key_i}(Y)\}\]

This expression quantifies the instances "i" where the outputs of the \textit{PreHash} function differ between samples \(X\) and \(Y\).

One notable advantage of this approach is the reduction in size of the stored biometric template. Rather than storing \textit{n} pixels, \textit{ml} integers are stored. Additionally, the key renders the reference \textit{PreHash} less privacy-sensitive compared to a biometric template. Specifically, if the key is known, each integer in the hash discloses about \(\frac{1}{p}\) pixels, revealing \(\frac{ml}{p}\) pixels at worst. This disclosure occurs because, with the keys, the hash values can potentially be reverse-engineered to reveal characteristics of the original biometric pattern. The term \(p\)â€‹ reflects the information entropy associated with each bit being a vein (\('1'\)) and thus quantifies the average information content each disclosed pixel conveys when the hash is decoded.

Similarly, when employing the Hamming distance for biometric matching through the iterative generation of \textit{l} iterations of the \textit{PostHash} function, analogous advantages arise. Here, the stored biometric template is condensed to \textit{mld} integers instead of \textit{n} pixels. Furthermore, the key diminishes the sensitivity of the reference \textit{PostHash} in terms of privacy, exposing \(\frac{mld}{p}\) pixels at most if known. Additionally, \textit{PostHash} contributes to leakage reduction.

It's crucial to note that for both scenarios, additional privacy safeguards can be implemented, for instance a restricted access to the key. Hence, the intricacies of the biometric infrastructure must be addressed on a case-by-case basis.

\subsection{Theoretical Foundations of FPR and FNR within Fuzzy Hashing Systems}

Transforming biometric data into a hash, using methods like \textit{PreHash} or its more compact version, \textit{PostHash}, plays a key role in enhancing the system's efficiency and security. This process helps protect privacy, which in turn influences important aspects of the system's performance, such as the \hyperref[def:FNR]{False Negative Rate (FNR)} and the \hyperref[def:FPR]{False Positive Rate (FPR)}. By converting detailed biometric data into a simpler, hashed format, the system not only uses storage space more efficiently but also reduces the chances of unauthorized access to sensitive information. This transformation is crucial for maintaining the integrity of the data and provides a strong line of defense against potential security threats. Additionally, choosing the right techniques for generating these hashes can greatly improve the system's ability to distinguish between authorized and unauthorized users. This means fewer mistakes in the form of false rejections or acceptances, leading to a more accurate and dependable biometric verification process.

We establish a threshold \(t\) to evaluate the match between two biometric samples, \(X\) and \(Y\), by analyzing the Hamming distance between their hash values.
We define that a match is confirmed if the difference between \(l\) (the total iterations) and the Hamming distance is equal to or exceeds the threshold \(t\), expressed as: \[l - d_H(Hash_{\text{key}}(X), Hash_{\text{key}}(Y)) \geq t\]
In contrast, we define there being no match if the following equation holds: \[l - d_H(Hash_{\text{key}}(X), Hash_{\text{key}}(Y)) < t\]

To further refine our understanding, we use statistical methods to approximate this comparison to a normal distribution, allowing us to more accurately calculate the False Negative Rate (FNR). This measure helps us assess how often the system incorrectly fails to recognize a match between the biometric samples when there actually is one. We define:

\begin{equation}
    \label{eq:fnr}
    FNR = \Phi\left( \frac{t - l\mu_{\text{same}}^m}{\sqrt{l\mu_{\text{same}}^m}} \right)
\end{equation}

Here, \(\Phi\) denotes the Cumulative Distribution Function (CDF) of the standard normal distribution, denoted as \(\mathcal{N}(0, 1)\).

In contrast, the False Positive Rate (FPR), the proportion of non-matching biometric samples incorrectly identified as matches by the system, is defined as:

\begin{equation}
    \label{eq:fpr}
    FPR = \Phi\left( \frac{t - l\mu_{\text{diff}}^m}{\sqrt{l\mu_{\text{diff}}^m}} \right)
\end{equation}

These formulations allow for the evaluation of false match rates based on the standard deviation and mean of the distributions for same and different samples, respectively. The upper bound \(\mu_{same}\) and \(\mu_{diff}\) are defined in Equation \ref{eq:mu}.

For instance, employing \(\Phi(-2.33) \approx 1\%\) as a benchmark, we calculate the threshold (\(t\)) from parameters \(m\) and \(l\) to achieve an FNR of 1\% and an FPR \(\leq 2^{-36} \). The resulting set of parameters is as follows: 

\begin{table}[htbp] 
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|}
        \hline
        \textit{m} & \textit{l} & \textit{t} & \textit{l}\(\mu_{\text{same}}^m\) & \textit{l}\(\mu_{\text{diff}}^m\) & \textit{FNR} & \textit{FPR} \\
        \hline
        1 & 637 & 118 & 146.6 & 49.2 & 1\% & \(2^{-37}\) \\
        2 & 961 & 34 & 50.0 & 5.7 & 1\% & \(2^{-38}\) \\
        3 & 2569 & 18 & 31.3 & 1.2 & 1\% & \(2^{-41}\) \\
        4 & 8481 & 12 & 23.8 & 0.3 & 1\% & \(2^{-43}\) \\
        5 & 32 999 & 11 & 21.3 & 0.1 & 1\% & \(2^{-51}\) \\
        6 & 140 090 & 10 & 20.8 & 0.0 & 1\% & \(2^{-67}\) \\
        7 & 568 315 & 9 & 19.5 & 0.0 & 1\% & \(2^{-51}\) \\
        8 & 2 841 573 & 11 & 22.4 & 0.0 & 1\% & \(2^{-120}\) \\
        \hline
    \end{tabular}
    \caption{Parameterization Results for FNR and FPR Calculation}
    \label{tab:parameterization}
\end{table}



\subsection{Experimental Derivation of the FPR and FNR for \(m = 1\) and \(d = 4\)}
In this subsection, we will experimentally evaluate the False Positive Rate (FPR) using compression techniques implemented through \textit{PostHash}, specifically compressing to \(D = 16\) (\(d=4\)). The introduction of compression slightly modifies the equations for false positive and false negative rates (Equations \ref{eq:fnr} and \ref{eq:fpr}), necessitating the use of \(q\) in place of \(\mu^m\). Our methodology involves processing our image dataset through a pipeline that initially applies \textit{PreHash} to generate a single index hash (\(m=1\)) for each of the \(l=637\) iterations. Subsequently, \textit{PostHash} compresses these indexes into 4-bit integers. We then compute the normalized Hamming distance between each image pair, with each image represented by \(l \times d\) bits. Lastly, we determine matches based on a specific threshold (\(t\)) tailored to the combined parameters of \(m=1\) and \(l=637\). To facilitate this experiment, we will derive the threshold \(t\) accordingly.