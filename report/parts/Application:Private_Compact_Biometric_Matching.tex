\newpage
\section{Application: Private and Compact Biometric Matching}
\label{Application: Private and Compact Biometric Matching}

This section delves into the practical application of fuzzy hashing within the realm of biometric matching. Employing the Hamming distance for biometric matching offers a systematic approach by iteratively generating \textit{l} iterations of the \textit{PreHash} function, defined as:

\begin{equation}
    \begin{aligned}
        Hash_{\text{key}}^m &= Hash_{\text{key}_1, \ldots, \text{key}_l}^m(X)\\
        &= (PreHash_{\text{key}_1}^m(X), \ldots, PreHash_{\text{key}_l}^m(X))
    \end{aligned}
\end{equation}

Subsequently, the Hamming distance between the resulting hash values of two biometric samples \(X\) and \(Y\) is calculated as:

\begin{equation}
    \begin{aligned}
        \label{eq:HammingDist}
        d_H(Hash_{key}(X), Hash_{key}(Y)) = \# \{i: PreHash_{key_i}(X) \neq PreHash_{key_i}(Y)\}
    \end{aligned}
\end{equation}

This expression quantifies the instances "i" where the outputs of the \textit{PreHash} function differ between samples \(X\) and \(Y\).

One notable advantage of this approach is the reduction in size of the stored biometric template. Rather than storing \textit{n} pixels, \textit{ml} integers are stored. Additionally, the key renders the reference \textit{PreHash} less privacy-sensitive compared to a biometric template. Specifically, if the key is known, each integer in the hash discloses about \(\frac{1}{p}\) pixels, revealing \(\frac{ml}{p}\) pixels at worst. This disclosure occurs because, with the keys, the hash values can potentially be reverse-engineered to reveal characteristics of the original biometric pattern. The term \(p\)​ reflects the information entropy associated with each bit being a vein (\('1'\)) and thus quantifies the average information content each disclosed pixel conveys when the hash is decoded.

Similarly, when employing the Hamming distance for biometric matching through the iterative generation of \textit{l} iterations of the \textit{PostHash} function, analogous advantages arise. Here, the stored biometric template is condensed to \textit{mld} integers instead of \textit{n} pixels. Furthermore, the key diminishes the sensitivity of the reference \textit{PostHash} in terms of privacy, exposing \(\frac{mld}{p}\) pixels at most if known. Additionally, \textit{PostHash} contributes to leakage reduction.

It's crucial to note that for both scenarios, additional privacy safeguards can be implemented, for instance a restricted access to the key. Hence, the intricacies of the biometric infrastructure must be addressed on a case-by-case basis.

\subsection{Theoretical Foundations of FPR and FNR within Fuzzy Hashing Systems}

Transforming biometric data into a hash, using methods like \textit{PreHash} or its more compact version, \textit{PostHash}, plays a key role in enhancing the system's efficiency and security. This process helps protect privacy, which in turn influences important aspects of the system's performance, such as the \hyperref[def:FNR]{False Negative Rate (FNR)} and the \hyperref[def:FPR]{False Positive Rate (FPR)}. By converting detailed biometric data into a simpler, hashed format, the system not only uses storage space more efficiently but also reduces the chances of unauthorized access to sensitive information. This transformation is crucial for maintaining the integrity of the data and provides a strong line of defense against potential security threats. Additionally, choosing the right techniques for generating these hashes can greatly improve the system's ability to distinguish between authorized and unauthorized users. This means fewer mistakes in the form of false rejections or acceptances, leading to a more accurate and dependable biometric verification process.

We establish a threshold \(t\) to evaluate the match between two biometric samples, \(X\) and \(Y\), by analyzing the Hamming distance between their hash values.
We define that a match is confirmed if the difference between \(l\) (the total iterations) and the Hamming distance is equal to or exceeds the threshold \(t\), expressed as: \[l - d_H(Hash_{\text{key}}(X), Hash_{\text{key}}(Y)) \geq t\]
In contrast, we define there being no match if the following equation holds: \[l - d_H(Hash_{\text{key}}(X), Hash_{\text{key}}(Y)) < t\]

To further refine our understanding, we use statistical methods to approximate this comparison to a normal distribution, allowing us to more accurately calculate the False Negative Rate (FNR). This measure helps us assess how often the system incorrectly fails to recognize a match between the biometric samples when there actually is one. We define:

\begin{equation}
    \label{eq:fnr}
    FNR = \Phi\left( \frac{t - l\mu_{\text{same}}^m}{\sqrt{l\mu_{\text{same}}^m}} \right)
\end{equation}

Here, \(\Phi\) denotes the Cumulative Distribution Function (CDF) of the standard normal distribution, denoted as \(\mathcal{N}(0, 1)\).

In contrast, the False Positive Rate (FPR), the proportion of non-matching biometric samples incorrectly identified as matches by the system, is defined as:

\begin{equation}
    \label{eq:fpr}
    FPR = \Phi\left(- \frac{t - l\mu_{\text{diff}}^m}{\sqrt{l\mu_{\text{diff}}^m}} \right)
\end{equation}

These formulations allow for the evaluation of false match rates based on the standard deviation and mean of the distributions for same and different samples, respectively. The upper bound \(\mu_{same}\) and \(\mu_{diff}\) are defined in Equation \ref{eq:mu}.

For instance, employing \(\Phi(-2.33) \approx 1\%\) as a benchmark, we calculate the threshold (\(t\)) from parameters \(m\) and \(l\) to achieve an FNR of 1\% and an FPR \(\leq 2^{-36} \). The theoretical resulting set of parameters is as follows: 

\begin{table}[htbp] 
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|}
        \hline
        \textit{m} & \textit{l} & \textit{t} & \textit{l}\(\mu_{\text{same}}^m\) & \textit{l}\(\mu_{\text{diff}}^m\) & \textit{FNR} & \textit{FPR} \\
        \hline
        1 & 217 & 32 & 47.84 & 17.9 & \(\leq\)1\% & \(2^{-11}\)\\
        1 & 637 & 113 & 140.44 & 52.55 & 1.0\% & \(2^{-54}\) \\
        %1 & 637 & 118 & 146.5 & 49 & 2^⁻6\% & \(2^{-74}\) \\
        2 & 961 & 31 & 46.71 & 6.54 & 1.0\% & \(2^{-70}\) \\
        %2 & 961 & 34 & 50.8 & 5.7 & 2^⁻6\% & \(2^⁻106\) \\
        3 & 2569 & 15 & 27.53 & 1.44 & 1.0\% &\(2^{-96}\) \\
        %3 & 2569 & 18 & 31.3 & 1.2 & 2^⁻6\% &\(2^{-179}\) \\
        4 & 8481 & 10 & 20.04 & 0.39 & 1.0\% & \(2^{-174}\) \\
        %4 & 8481 & 12 & 23.7 & 0.3 & 2^⁻6\% &\(2^{-377}\) \\
        5 & 32 999 & 8 & 17.19 & 0.13 & 1.0\% & \(2^{-360}\) \\
        \hline
    \end{tabular}
    \caption{Theoretical Parameterization Results for FNR and FPR Calculation, using $l$ Iterations of PreHash}
    \label{tab:theoretical_parameterization_PreHash}
\end{table}

Using compression techniques implemented through \textit{PostHash}, specifically compressing to \( D = 16 \) (\( d = 4 \)), we calculate the threshold (\( t \)) from parameters \( m = 1 \) and \( l \) to achieve an FNR of \(1\%\) and an FPR \(\leq 2^{-36} \). The introduction of compression slightly modifies the equations for FNR (\ref{eq:fnr}) and FPR (\ref{eq:fpr}), necessitating the use of \( q \) in place of \(\mu^m\). The theoretical resulting set of parameters is as follows:

\begin{table}[htbp] 
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|c|}
        \hline
        \textit{m} & \textit{d} & \textit{l} & \textit{t} & \textit{l}\(q_{\text{same}}^m\) & \textit{l}\(q_{\text{diff}}^m\) & \textit{FNR} & \textit{FPR} \\
        \hline
        1 & 4 & 1107 & 276 & 317.7 & 130.6 & 1.0\% & \(2^{-121}\) \\
        1 & 4 & 347 & 76 & 99.6 & 40.9 & \(\leq\)1.0\% & \(2^{-14}\)\\
        1 & 1 & 3597 & 957 & 1032.3 & 424.4 & \(\leq\)1.0\% & \(2^{-488}\)\\
        \hline
    \end{tabular}
    \caption{Theoretical Parameterization Results for FNR and FPR Calculation, using $l$ Iterations of PostHash}
    \label{tab:theoretical_parameterization_PostHash}
\end{table}

\subsection{Experimental Derivation of the FNR and FPR for different (\(m, l\)) Parameter Configurations}

To experimentally determine the False Negative Rate (FNR) and the False Positive Rate (FPR) for various \((m, l)\) parameter configurations, the initial step is to compute the Hamming distance between \( Hash_{\text{key}}(X) \) and \( Hash_{\text{key}}(Y) \). The \( Hash_{\text{key}} \) of an extracted feature vector is generated using \( l \) iterations of \textit{PreHash}. We designed an algorithm that accepts a list of \( l \) keys (since each \textit{PreHash} iteration requires a new key) and the parameter \( m \), which indicates the number of indices each call to \textit{PreHash} should generate per key. For testing purposes, the \( l \) keys are simply integers from 0 to \( l-1 \), converted into a two-byte binary format. We then calculate the Hamming distance between the resulting hash values for pairs of images. The Hamming distance between \( Hash_{\text{key}}(X) \) and \( Hash_{\text{key}}(Y) \) is defined as the number of positions at which the corresponding iterations of \textit{PreHash} are different, as defined in Equation \ref{eq:HammingDist}. In this formula, the expression \( \# \{ i : PreHash_{\text{key}_i}(X) \neq PreHash_{\text{key}_i}(Y) \} \) counts the number of iterations \( i \) where the pre-hash values of \( X \) and \( Y \) differ. Each comparison results in a \(1\) if the iterations differ and a \(0\) if they are the same. Summing these comparison results gives the total number of differing positions, thereby computing the Hamming distance between the hash values of the iterations.


Each experiment we conducted uses a different row from Table \ref{tab:theoretical_parameterization_PostHash}. In each experiment, we generate \( l \) \textit{PreHash} iterations for all image pairs and then determine if two images, \(X\) and \(Y\), are a match, defined as \( l - d_H(Hash_{\text{key}}(X), Hash_{\text{key}}(Y)) \geq t \). We perform two types of comparisons on our data:

\begin{enumerate}
    \item \textbf{Same Person, Same Finger Comparisons}: This involves comparing different trials of images from the same person and the same finger. These comparisons should theoretically result in a match. If two such images do not match (i.e., \( l - d_H(Hash_{\text{key}}(X), Hash_{\text{key}}(Y)) < t \)), this contributes to the FNR.
    \item \textbf{Different People or Fingers Comparisons}: This involves comparing images from different people and/or different fingers. These comparisons should theoretically not result in a match. If two such images do match, this contributes to the FPR.
\end{enumerate}

To calculate the False Negative Rate (FNR), we count the instances where images that should match do not, and then compute the mean of these instances. Similarly, for the False Positive Rate (FPR), we count the instances where images that should not match do, and then compute the mean of these instances.

For the experiments from Table \ref{tab:theoretical_parameterization_PostHash}, we obtain the following results:

\begin{enumerate}
    \item \textbf{m = 1, l = 217 and t = 32}
        \begin{itemize}
            \item $FNR = 18.91\%$
            \item $FPR = 2^{-9}$
        \end{itemize}
    \item \textbf{m = 1, l = 637 and t = 113}
        \begin{itemize}
            \item $FNR = 31.75\%$
            \item $FPR = 2^{-14}$ 
        \end{itemize}
    \item \textbf{m = 2, l = 961 and t = 31}
        \begin{itemize}
            \item  $FNR = 33.32\%$
            \item $FPR = 2^{-14}$
        \end{itemize}
    \item \textbf{m = 3, l = 2569 and t = 15}
        \begin{itemize}
            \item $FNR = 33.45\%$
            \item $FPR = 2^{-13}$ 
        \end{itemize}
    \item \textbf{m = 4, l = 8481 and t = 10}
        \begin{itemize}
            \item FPR: 
            \item FNR: 
        \end{itemize}
    \item \textbf{m = 5, l = 32'999 and t = 8}
        \begin{itemize}
            \item FPR: 
            \item FNR: 
        \end{itemize}
\end{enumerate}


\subsection{Experimental Derivation of the FNR and FPR for different (\(m, l, d\)) Parameter Configurations with Compression}

In this subsection, we will experimentally evaluate the False Negative Rate (FNR) and False Positive Rate (FPR) with compression. We designed an algorithm that uses the previously defined method to generate \( l \) iterations of \textit{PreHash} and then compresses each hash value generated depending on the value of \(D = 2^d\). For an image, the algorithm generates a list of the \( l \) iterations of \textit{PreHash} and then applies the \textit{PostHash} algorithm to each \textit{PreHash} output.

After both images pass through this process, each iteration of each image is compared, resulting in a 1 if the iterations differ and a 0 if they are the same. Summing these comparison results gives the total number of ones, effectively computing the Hamming distance between the compressed and hashed images.

\begin{enumerate}
    \item \textbf{d = 4, m = 1, l = 1107 and t = 276}
        \begin{itemize}
            \item FPR: 
            \item FNR: 
        \end{itemize}
    \item \textbf{d = 4, m = 1, l = 347 and t = 76}
        \begin{itemize}
            \item FPR: 
            \item FNR: 
        \end{itemize}
    \item \textbf{d = 1, m = 1, l = 3'597 and t = 957}
        \begin{itemize}
            \item FPR: 
            \item FNR: 
        \end{itemize}
\end{enumerate}
