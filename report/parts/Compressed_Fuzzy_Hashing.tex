\newpage
\include{Fuzzy_Hashing.tex}

\section{Compressed Fuzzy Hashing}
\label{sec:Compressed Fuzzy Hashing}

Compressed fuzzy hashing generates concise hashes of files or data, capturing key features while allowing for slight variations - a concept referred to as "fuzziness". Unlike traditional cryptographic hashing methods, which produce fixed-length hashes vulnerable to significant changes even with minor input alterations, compressed fuzzy hashing offers greater resilience. Even when alterations occur, the hashing algorithm can still identify similar content. 

This section delves into the implementation of the compressed fuzzy hashing algorithm, known as \textit{PostHash}, its underlying mathematical principles, and present certain experimental results.

\subsection{PostHashing Algorithm}

The \textit{PostHash} algorithm, constituting the second step in the fuzzy hashing process, generates compact hashes based on the indices derived from the \textit{PreHash} algorithm (see section \ref{sec:Fuzzy Hashing}). It maps a list of indices to a hash \(h_1|| \ldots || h_m\), where each \(h_i\) \(i \in [1, m]\), is an integer in the range \([0, \ldots, D-1]\). Here, \(D = 2^d\), with d indicating the number of bits used to represent a single index. 

Algorithm Inputs and Outputs:
\begin{enumerate}
    \item \textbf{Inputs}: As illustrated in Figure~\ref{postHash Algorithm}, the algorithm takes as input:
    \begin{itemize}
        \item \textbf{A tuple of indices}: A tuple of indices \((i_1, \ldots, i_m)\), which is the output of the \textit{PreHash} algorithm
    \end{itemize}
    \item \textbf{Output}: Converted indices, forming a compact hash \(h_1|| \ldots || h_m\), where \(h_i\) \(i \in [1, m]\), is an integer in \([0, \ldots, D-1]\)
\end{enumerate} 

Detailed Process of \textit{PostHash}:
\begin{itemize}
    \item \textbf{Subroutine}: For each index produced by the \textit{PreHash} algorithm, \textit{PostHash} employs a subroutine \(T\) (see Figure ~\ref{Subroutine Algorithm}). This subroutine returns 0 if the input is out of range and performs a table lookup otherwise. It maps an index \(i\) to an integer nearly uniformly distributed between \([0, D-1]\). The implementation is as follows:
    \begin{itemize}
        \item \textbf{Inputs}: 
        \begin{itemize}
            \item \textbf{Index}: The index in the indices array that we wish to convert
            \item \textbf{d}: Bitlength of the desired hash index, indicating the number of bits used to represent a single index \(h_i\) \(i \in [1, m]\). The relationship \(D = 2^d\) expresses the total number of possible hash indices that can be represented with d bits
        \end{itemize}
        \item \textbf{Output}: \(h_i\), the mapped integer
    \end{itemize}
\end{itemize}

The \textit{postHash} algorithm generates integers \(h_1 || \ldots || h_m\), where each \(h_i \in [0, D-1]\). Here, \(D = 2^d\), with \(d\) indicating the number of bits used to represent a single index. 

\begin{algorithm}
    \begin{algorithmic}[1]
    \caption{\textit{postHash} Algorithm}
    \label{postHash Algorithm}
    \Function{(postHash $\circ$ preHash$_\text{key}^m$)}{$X$}
    \State $\text{hash} = []$
    \State $i' \gets 0$
    \For{$i \in \text{indices}$}
        \State $h_i \gets \text{Subroutine}(i - i', d)$
        \State $\text{hash.append}(h_i)$
        \State $i' \gets i$
    \EndFor 
    \State \Return{$h_1, \ldots, h_m$}
    \EndFunction
    \end{algorithmic}
    \end{algorithm}
    
    \begin{algorithm}
    \begin{algorithmic}[1]
    \caption{\textit{Subroutine} Algorithm}
    \label{Subroutine Algorithm}
    \Function{\text{Subroutine}}{$i$, $d$}
    \State $p = 0.0329$
    \State $h_i = \lfloor 2^d (1-p)^{i} \rfloor$
    \State \Return{$h_i$}
    \EndFunction
    \end{algorithmic}
    \end{algorithm}

\subsection{Assessing Similarity of Biometric Inputs After PostHash Application}
\label{sec:q}

After processing the finger images through the pipeline outlined in Pipeline~\ref{pipeline_simon} to extract their feature vectors, and subsequently applying the \textit{postHash} algorithm to the output of \textit{preHash}, the result comprises a set of integers falling within the inclusive range \(h_i \in [0, D-1]\), effectively assigning each index to an integer.

Our methodology assumes that these integers \(h_i\) follow a geometric distribution, with the hash length parameter \(m\) set to \(1\) for generating single-integer hashes. Given that the input for \textit{postHash} is the output of \textit{preHash}, let us denote this relationship as \(Hash_{key}^m(X) = \text{postHash}(\text{preHash}_{key}^m(X))\). We assume the same conditions as discussed in Section~\ref{sec:Fuzzy Hashing}: the key is randomly chosen, and \(k\) represents a uniformly distributed random index. Consequently, the probability of the \textit{Hash} operation yielding the same index for two different inputs \(X\) and \(Y\) can be mathematically characterized as follows:

\[Pr[Hash_{key}^m(d_X) = Hash_{key}^m(d_Y)] \leq \mu^m(1 - \frac{1}{D}) + \frac{1}{D}\]

where equality is reached for the optimal offset translations. 

Depending on the distribution of \(X\), \(Y\) it is denoted

\[q = \mu^m(1 - \frac{1}{D}) + \frac{1}{D}\]

Depending on the values that \(d\) can take on, we computed a few values:
\begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.25}\begin{tabular}{|c|c|c|c|}
        \hline
        & $q_{same}$ & $q_{diff}$ & $q_{indep}$\\
        \hline
        m = 1 d = 1 & $60\%$ & $54\%$ & $51\%$\\
        m = 1 d = 2 & $40\%$ & $31\%$ & $26\%$\\
        m = 1 d = 3 & $30\%$ & $20\%$ & $14\%$\\
        m = 1 d = 4 & $25\%$ & $14\%$ & $8\%$\\
        \hline
    \end{tabular}
\caption{Comparison of Distributions: $q_{same}$, $q_{diff}$, and $q_{indep}$}
\end{table}

\subsection{Data Compression Techniques for m=1, d=4}

{
\renewcommand{\arraystretch}{1.25}
\[
\text{postHash}(i) = \left\{
\begin{array}{lll}
    \text{15} & \text{if } i = 1 & (\text{Pr} = 3.29\%), \\
    \text{14} & \text{if } 2 \leq i \leq 3 & (\text{Pr} = 6.26\%), \\
    \text{13} & \text{if } 4 \leq i \leq 6 & (\text{Pr} = 8.64\%), \\
    \text{12} & \text{if } 7 \leq i \leq 8 & (\text{Pr} = 5.3\%), \\
    \text{11} & \text{if } 9 \leq i \leq 11 & (\text{Pr} = 7.31\%), \\
    \text{10} & \text{if } 12 \leq i \leq 14 & (\text{Pr} = 6.61\%), \\
    \text{9} & \text{if } 15 \leq i \leq 17 & (\text{Pr} = 6\%), \\
    \text{8} & \text{if } 18 \leq i \leq 20 & (\text{Pr} = 5.41\%), \\
    \text{7} & \text{if } 21 \leq i \leq 24 & (\text{Pr} = 6.41\%), \\
    \text{6} & \text{if } 25 \leq i \leq 29 & (\text{Pr} = 6.9\%), \\
    \text{5} & \text{if } 30 \leq i \leq 34 & (\text{Pr} = 5.83\%), \\
    \text{4} & \text{if } 35 \leq i \leq 41 & (\text{Pr} = 6.7\%), \\
    \text{3} & \text{if } 42 \leq i \leq 50 & (\text{Pr} = 6.6\%), \\
    \text{2} & \text{if } 51 \leq i \leq 62 & (\text{Pr} = 6.2\%), \\
    \text{1} & \text{if } 63 \leq i \leq 82 & (\text{Pr} = 6.13\%), \\
    \text{0} & \text{if } 83 \leq i \leq n & (\text{Pr} = 6.43\%),
\end{array}
\right.
\]
}


Scrambled Domain

\renewcommand{\arraystretch}{1.25}{
\[
\text{postHash}(i) = \left\{
\begin{array}{lll}
    15 & \text{if } i \in \{1\} \cup \{4\} & (\text{Pr} = 6.27\%), \\
    14 & \text{if } i \in \{2, 3\} & (\text{Pr} = 6.26\%), \\
    13 & \text{if } i \in \makecell[tl]{\{5, 6\} \cup \{53\}} & (\text{Pr} = 6.24\%), \\
    12 & \text{if } i \in \makecell[tl]{\{7, 8\} \cup \{38\}} & (\text{Pr} = 6.25\%), \\
    11 & \text{if } i \in \makecell[tl]{\{9, 10\} \cup \{29\}} & (\text{Pr} = 6.25\%), \\
    10 & \text{if } i \in \makecell[tl]{\{12, 13\} \cup \{83\} \cup \{85, \ldots, 92\} \\ \cup \{99\} \cup \{170\}} & (\text{Pr} = 6.24\%), \\
    9  & \text{if } i \in \makecell[tl]{\{15, \ldots, 17\} \cup \{78\}} & (\text{Pr} = 6.25\%), \\
    8  & \text{if } i \in \makecell[tl]{\{18, \ldots, 20\} \cup \{42\}} & (\text{Pr} = 6.24\%), \\
    7  & \text{if } i \in \makecell[tl]{\{21, \ldots, 23\} \cup \{63, 64\} \cup \{71\}} & (\text{Pr} = 6.25\%), \\
    6  & \text{if } i \in \makecell[tl]{\{25, \ldots, 28\} \cup \{61\} \cup \{84\}} & (\text{Pr} = 6.25\%), \\
    5  & \text{if } i \in \makecell[tl]{\{30, \ldots, 34\} \cup \{62\}} & (\text{Pr} = 6.26\%), \\
    4  & \text{if } i \in \makecell[tl]{\{35, \ldots, 37\} \cup \{39, \ldots, 41\} \cup \{57\}} & (\text{Pr} = 6.26\%), \\
    3  & \text{if } i \in \makecell[tl]{\{43, \ldots, 50\} \cup \{59\}} & (\text{Pr} = 6.24\%), \\
    2  & \text{if } i \in \makecell[tl]{\{11\} \cup \{51, 52\} \cup \{54, \ldots, 56\} \\ \cup \{58\} \cup \{60\} \cup \{98\}} & (\text{Pr} = 6.25\%), \\
    1  & \text{if } i \in \makecell[tl]{\{24\} \cup \{65, \ldots, 70\} \cup \{72, \ldots, 77\} \\ \cup \{79, \ldots, 82\}} & (\text{Pr} = 6.25\%), \\
    0  & \text{if } i \in \makecell[tl]{\{14\} \cup \{93, \ldots, 97\} \cup \{101\} \\ \cup \{103, \ldots, 169\} \cup \{171, \ldots, n\}} & (\text{Pr} = 6.24\%)
\end{array}
\right.
\]
}




\subsection{Efficiency Improvement in Hashing Process}